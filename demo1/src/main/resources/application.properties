###################Redis 配置#######################
redis.database = 0
redis.host = 127.0.0.1
redis.port = 6379
redis.password = 123456
redis.timeout = 2000
redis.cache.timeout = 60
#Redis Pool配置
#redis连接池最大链接数
redis.pool.maxActive = 200
#redis获取链接最大等待时间毫秒
redis.pool.maxWait = 3000
#redis连接池空闲时最大连接数
redis.pool.maxIdle = 8
redis.pool.minIdle = 1

###################MySQL配置#######################
jdbc.type = com.alibaba.druid.pool.DruidDataSource
jdbc.url = jdbc:mysql://127.0.0.1:3306/db_test?useUnicode=true&characterEncoding=utf8&allowMultiQueries=true&serverTimezone=Asia/Shanghai
jdbc.username = root
jdbc.password = 046317
jdbc.driver-class-name = com.mysql.cj.jdbc.Driver
jdbc.initial-size = 5
jdbc.min-idle = 5
jdbc.max-active = 20
jdbc.max-wait = 30000
jdbc.time-between-eviction-runs-millis = 60000
jdbc.min-evictable-idle-time-millis = 300000
jdbc.validation-query = select '1' from dual
jdbc.test-while-idle = true
jdbc.test-on-borrow = false
jdbc.test-on-return = false
jdbc.pool-prepared-statements = true
jdbc.max-pool-prepared-statement-per-connection-size = 20
jdbc.filters = stat
jdbc.connection-properties = druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
jdbc.use-global-data-source-stat = true


#####################kafka配置#####################
#指定kafka 代理地址，可以多个
kafka.bootstrapServers = 127.0.0.1:9092
#指定默认消费者group id
kafka.consumer.groupId = 0
#指定默认topic id
kafka.consumer.topic = ljl-kafka-test2
#是否自动提交消费成功
kafka.consumer.enableAutoCommit = false
kafka.consumer.autoCommitIntervalMs = 1000
kafka.consumer.sessionTimeoutMs = 30000
#批量消费最大数据条数
kafka.consumer.maxPollRecords = 10
#earliest,latest
#若设置为earliest，那么会从头开始读partition
kafka.consumer.autoOffsetReset = earliest
#指定listener 容器中的线程数，用于提高并发量
kafka.consumer.concurrency2 = 10
#打点
#producer
kafka.producer.topic = ljl-kafka-test2
kafka.producer.retries = 0
kafka.producer.batch.size = 4096
kafka.producer.linger = 1
kafka.producer.buffer.memory = 40960
##all ISR都收到确认信息  0 发送就删除了  1 主节点收到就删除了
kafka.producer.acks = all

###################elasticsearch配置#####################
# elasticsearch集群名称，默认的是elasticsearch
spring.data.elasticsearch.cluster-name=my-application
#节点的地址 注意api模式下端口号是9300，千万不要写成9200
spring.data.elasticsearch.cluster-nodes=localhost:9300
#是否开启本地存储
spring.data.elasticsearch.repositories.enable=true